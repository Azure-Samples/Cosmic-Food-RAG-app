{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install langchain==0.3.14\n",
    "%pip install langchain-openai==0.2.14\n",
    "%pip install pymongo==4.10.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load Environment Variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create .env file if it doesn't exist\n",
    "%cp -n .env.example .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load the environment variables from .env file\n",
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\".env\", override=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the `api_type`, `base_url`, `api_version`, and `api_key` as global variables to avoid the need to supply them later in code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "\n",
    "openai.api_type = os.getenv(\"OPENAI_API_TYPE\", \"azure\")\n",
    "openai.base_url = os.getenv(\"AZURE_OPENAI_ENDPOINT\", \"https://<YOUR-OPENAI-DEPLOYMENT-NAME>.openai.azure.com/\")\n",
    "openai.api_version = os.getenv(\"OPENAI_API_VERSION\", \"2023-09-15-preview\")\n",
    "openai.api_key = os.getenv(\"OPENAI_API_KEY\", \"<YOUR-DEPLOYMENT-KEY>\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intialize the MongoDB Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/db/x_x115ns61154jxycm1mwr780000gn/T/ipykernel_54773/1277193319.py:17: UserWarning: You appear to be connected to a CosmosDB cluster. For more information regarding feature compatibility and support please visit https://www.mongodb.com/supportability/cosmosdb\n",
      "  mongo_client = MongoClient(mongo_connection_string)\n"
     ]
    }
   ],
   "source": [
    "from urllib.parse import quote_plus\n",
    "\n",
    "from pymongo import MongoClient\n",
    "\n",
    "# Read and Store Environment variables\n",
    "mongo_connection_string = os.getenv(\"AZURE_COSMOS_CONNECTION_STRING\", \"<YOUR-COSMOS-DB-CONNECTION-STRING>\")\n",
    "mongo_username = quote_plus(os.getenv(\"AZURE_COSMOS_USERNAME\"))\n",
    "mongo_password = quote_plus(os.getenv(\"AZURE_COSMOS_PASSWORD\"))\n",
    "mongo_connection_string = mongo_connection_string.replace(\"<user>\", mongo_username).replace(\n",
    "    \"<password>\", mongo_password\n",
    ")\n",
    "\n",
    "collection_name = os.getenv(\"AZURE_COSMOS_COLLECTION_NAME\", \"collectionName\")\n",
    "database_name = os.getenv(\"AZURE_COSMOS_DATABASE_NAME\", \"DatabaseName\")\n",
    "\n",
    "# Initialize the MongoClient\n",
    "mongo_client = MongoClient(mongo_connection_string)\n",
    "\n",
    "# Create the database if it doesn't exist\n",
    "db = mongo_client[database_name]\n",
    "\n",
    "# Create the collection if it doesn't exist\n",
    "collection = db[collection_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load JSON Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from langchain.docstore.document import Document\n",
    "\n",
    "SOURCE_FILE_NAME = \"./src/data/food_items.json\"\n",
    "\n",
    "\n",
    "def read_data(file_path) -> list[Document]:\n",
    "    # Load JSON file\n",
    "    with open(file_path) as file:\n",
    "        json_data = json.load(file)\n",
    "\n",
    "    documents = []\n",
    "    absolute_path = os.path.abspath(file_path)\n",
    "    # Process each item in the JSON data\n",
    "    for idx, item in enumerate(json_data):\n",
    "        documents.append(\n",
    "            Document(page_content=json.dumps(item), metadata={\"source\": absolute_path, \"seq_num\": idx + 1})\n",
    "        )\n",
    "\n",
    "    return documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = read_data(SOURCE_FILE_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "page_content='{\"category\": \"Smoothies\", \"name\": \"Jimmy Jam Smoothie\", \"description\": \"Berries n kale, strawberries, bananas, blueberries kale, tropical fruit blend, and dragon fruit. Our fruity tasty smoothies are blended to perfection.\", \"price\": \"5.49 USD\"}' metadata={'source': '/Users/john0isaac/Developer/Cosmic-Food-RAG-app/src/data/food_items.json', 'seq_num': 2}\n"
     ]
    }
   ],
   "source": [
    "# Display a sample from the data\n",
    "print(json_data[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Embeddings Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureOpenAIEmbeddings\n",
    "\n",
    "openai_embeddings_model = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_MODEL_NAME\", \"text-embedding-ada-002\")\n",
    "openai_embeddings_deployment = os.getenv(\"AZURE_OPENAI_EMBEDDINGS_DEPLOYMENT_NAME\", \"text-embedding\")\n",
    "\n",
    "azure_openai_embeddings: AzureOpenAIEmbeddings = AzureOpenAIEmbeddings(\n",
    "    model=openai_embeddings_model,\n",
    "    azure_deployment=openai_embeddings_deployment,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate and Save Embeddings to MongoDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.azure_cosmos_db import AzureCosmosDBVectorSearch\n",
    "\n",
    "index_name = os.getenv(\"AZURE_COSMOS_INDEX_NAME\", \"indexName\")\n",
    "\n",
    "# Only Run this the first time you open the notebook\n",
    "# Create embeddings from the data, save to the database and return a connection to MongoDB vCore\n",
    "vector_store: AzureCosmosDBVectorSearch = AzureCosmosDBVectorSearch.from_documents(\n",
    "    json_data,\n",
    "    azure_openai_embeddings,\n",
    "    collection=collection,\n",
    "    index_name=index_name,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.vectorstores.azure_cosmos_db import AzureCosmosDBVectorSearch\n",
    "\n",
    "# Run this to connect to the vector store\n",
    "vector_store: AzureCosmosDBVectorSearch = AzureCosmosDBVectorSearch.from_connection_string(\n",
    "    connection_string=mongo_connection_string,\n",
    "    namespace=f\"{database_name}.{collection_name}\",\n",
    "    embedding=azure_openai_embeddings,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Vector Index (HNSW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'raw': {'defaultShard': {'numIndexesBefore': 1,\n",
       "   'numIndexesAfter': 2,\n",
       "   'createdCollectionAutomatically': False,\n",
       "   'ok': 1}},\n",
       " 'ok': 1}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.vectorstores.azure_cosmos_db import (\n",
    "    CosmosDBSimilarityType,\n",
    "    CosmosDBVectorSearchType,\n",
    ")\n",
    "\n",
    "# Read more about these variables in detail here. https://learn.microsoft.com/en-us/azure/cosmos-db/mongodb/vcore/vector-search\n",
    "num_lists = 100\n",
    "dimensions = 1536\n",
    "similarity_algorithm = CosmosDBSimilarityType.COS\n",
    "kind = CosmosDBVectorSearchType.VECTOR_HNSW\n",
    "m = 16\n",
    "ef_construction = 64\n",
    "\n",
    "# Create the collection and the index\n",
    "vector_store.create_index(num_lists, dimensions, similarity_algorithm, kind, m, ef_construction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Vector Search Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"category\": \"Sandwiches\", \"name\": \"Bacon Turkey Bravo Sandwich\", \"description\": \"Whole (1010 Cal.), Half (500 Cal.) Oven-roasted turkey breast raised without antibiotics, Applewood-smoked bacon, smoked Gouda, emerald greens, vine-ripened tomatoes, signature sauce , salt and pepper on Tomato Basil Bread. Allergens: Contains Wheat, Milk, Egg\", \"price\": \"8.79 USD\"}\n"
     ]
    }
   ],
   "source": [
    "query = \"Beef Bacon\"\n",
    "docs = vector_store.similarity_search(query)\n",
    "print(docs[0].page_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the Chat Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import AzureChatOpenAI\n",
    "\n",
    "openai_chat_model = os.getenv(\"AZURE_OPENAI_CHAT_MODEL_NAME\", \"gpt-35-turbo\")\n",
    "openai_chat_deployment = os.getenv(\"AZURE_OPENAI_CHAT_DEPLOYMENT_NAME\", \"chat-gpt\")\n",
    "\n",
    "azure_openai_chat: AzureChatOpenAI = AzureChatOpenAI(\n",
    "    model=openai_chat_model,\n",
    "    azure_deployment=openai_chat_deployment,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why don't scientists trust atoms?\n",
      "\n",
      "Because they make up everything!\n"
     ]
    }
   ],
   "source": [
    "# Test the chat flow\n",
    "chat_response = azure_openai_chat.invoke(\"Tell me a joke\")\n",
    "print(chat_response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Education is a fundamental aspect of human development. It plays a pivotal role in shaping individuals' minds, fostering critical thinking skills, and equipping them with the necessary knowledge and skills to succeed in life. Education is not confined to the walls of a classroom; it encompasses a broader spectrum of learning experiences that occur throughout a person's lifetime.\n",
      "\n",
      "Firstly, education provides individuals with a solid foundation of knowledge. From basic literacy and numeracy skills to more advanced subjects like science, history, and literature, education broadens our understanding of the world around us. It helps us make informed decisions and enables us to contribute meaningfully to society.\n",
      "\n",
      "Furthermore, education fosters critical thinking and problem-solving skills. It encourages individuals to question, analyze, and think independently. Through various teaching methods such as discussions, research projects, and practical applications, education promotes creativity and innovation. It equips individuals with the ability to tackle challenges and find solutions, preparing them for the complexities of the modern world.\n",
      "\n",
      "Education also empowers individuals by providing them with opportunities for personal and professional growth. It opens doors to better job prospects, higher earning potential, and improved social status. Moreover, education promotes lifelong learning, allowing individuals to adapt to changing circumstances and acquire new skills throughout their lives.\n",
      "\n",
      "In conclusion, education is a powerful tool that has the potential to transform lives. It instills a love for learning, nurtures critical thinking skills, and empowers individuals to reach their full potential. By investing in education, societies can pave the way for a brighter future, where individuals are equipped with the knowledge and skills to overcome challenges and contribute positively to their communities."
     ]
    }
   ],
   "source": [
    "chat_response = azure_openai_chat.astream(\"Write a 200 words essay about education.\")\n",
    "\n",
    "async for response in chat_response:\n",
    "    print(response.content, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create RAG Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "REPHRASE_PROMPT = \"\"\"\\\n",
    "Given the following conversation and a follow up question, rephrase the follow up \\\n",
    "question to be a standalone question.\n",
    "\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone Question:\"\"\"\n",
    "\n",
    "CONTEXT_PROMPT = \"\"\"\\\n",
    "You are a restaurant chatbot, tasked with answering any question about \\\n",
    "food dishes from the contex.\n",
    "\n",
    "Generate a response of 80 words or less for the \\\n",
    "given question based solely on the provided search results (name, description, price, and category). \\\n",
    "You must only use information from the provided search results. Use an unbiased and \\\n",
    "fun tone. Do not repeat text. Your response must be solely based on the provided context.\n",
    "\n",
    "If there is nothing in the context relevant to the question at hand, just say \"Hmm, \\\n",
    "I'm not sure.\" Don't try to make up an answer.\n",
    "\n",
    "Anything between the following `context` html blocks is retrieved from a knowledge \\\n",
    "bank, not part of the conversation with the user. \n",
    "\n",
    "<context>\n",
    "    {context} \n",
    "<context/>\n",
    "\n",
    "REMEMBER: If there is no relevant information within the context, just say \"Hmm, I'm \\\n",
    "not sure.\" Don't try to make up an answer. Anything between the preceding 'context' \\\n",
    "html blocks is retrieved from a knowledge bank, not part of the conversation with the \\\n",
    "user.\\\n",
    "\n",
    "User Question: {input}\n",
    "\n",
    "Chatbot Response:\"\"\"\n",
    "\n",
    "rephrase_prompt_template = ChatPromptTemplate.from_template(REPHRASE_PROMPT)\n",
    "context_prompt_template = ChatPromptTemplate.from_template(CONTEXT_PROMPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "limit = 3\n",
    "score_threshold = 0.5\n",
    "search_type = \"similarity\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from quartapp.approaches.rag import get_data_points\n",
    "\n",
    "# Vector Store Retriever\n",
    "vector_store_retriever = vector_store.as_retriever(\n",
    "    search_type=search_type, search_kwargs={\"k\": limit, \"score_threshold\": score_threshold}\n",
    ")\n",
    "# Rephrase Chain\n",
    "rephrase_chain = rephrase_prompt_template | azure_openai_chat\n",
    "# Context Chain\n",
    "context_chain = context_prompt_template | azure_openai_chat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test RAG Flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What vegan options do you have?\n"
     ]
    }
   ],
   "source": [
    "# 1. Rephrase the question\n",
    "messages = [{\"content\": \"Do you have any vegan options?\", \"role\": \"user\"}]\n",
    "\n",
    "rephrased_question = rephrase_chain.invoke({\"chat_history\": messages[:-1], \"question\": messages[-1]})\n",
    "print(rephrased_question.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[DataPoint(name='Beyond Burger', description='Served with Romaine lettuce, tomato, pickle, vegan mayonnaise, ketchup, and mustard on a toasted bun. Sandwich made with whole wheat bread. Can be made as a wrap in a whole wheat tortilla. Served with kettle potato chips or corn tortilla chips.', price='9.0 USD', category='Sandwiches', collection=None), DataPoint(name='Tofu Salad Sandwich', description='Served with Romaine lettuce, tomato, vegan mayonnaise, and mustard. Sandwich made with whole wheat bread. Can be made as a wrap in a whole wheat tortilla. Served with kettle potato chips or corn tortilla chips.', price='9.0 USD', category='Sandwiches', collection=None)]\n"
     ]
    }
   ],
   "source": [
    "# 2. Get the context from the database and format it to remove the embeddings\n",
    "vector_context = vector_store_retriever.invoke(str(rephrased_question.content))\n",
    "data_points = get_data_points(vector_context)\n",
    "print(data_points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have a couple of delicious vegan options for you! Our Beyond Burger is made with plant-based ingredients and served with lettuce, tomato, pickle, vegan mayo, ketchup, and mustard on a toasted bun. We also have a Tofu Salad Sandwich with lettuce, tomato, vegan mayo, and mustard. Both sandwiches can be made as wraps and come with kettle potato chips or corn tortilla chips. They are priced at $9. Enjoy your vegan meal!\n"
     ]
    }
   ],
   "source": [
    "# 3. Generate a response based on the context\n",
    "response = context_chain.invoke({\"context\": [dp.to_dict() for dp in data_points], \"input\": rephrased_question.content})\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Store the chat history and the response\n",
    "messages.append({\"content\": response.content, \"role\": \"assistant\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with another question to see if the chat history is maintained\n",
    "messages.append({\"content\": \"what is the price of the first dish?\", \"role\": \"user\"})\n",
    "\n",
    "rephrased_question = rephrase_chain.invoke({\"chat_history\": messages[:-1], \"question\": messages[-1]})\n",
    "vector_context = vector_store_retriever.invoke(str(rephrased_question.content))\n",
    "data_points = get_data_points(vector_context)\n",
    "response = context_chain.invoke({\"context\": [dp.to_dict() for dp in data_points], \"input\": rephrased_question.content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rephrased Question:  What is the price of the first vegan dish?\n",
      "LLM Response:  The price of the first vegan dish, Veggie Samosa, is 8.35 USD. Enjoy these triangular pastries filled with spiced potatoes, peas, and lentils, served with a side of mint or tamarind relish!\n"
     ]
    }
   ],
   "source": [
    "print(\"Rephrased Question: \", rephrased_question.content)\n",
    "print(\"LLM Response: \", response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inline Embeddings Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_connection_string = os.getenv(\"AZURE_COSMOS_CONNECTION_STRING_AUTO_EMBEDDING\", \"conn_string\")\n",
    "mongo_client = MongoClient(mongo_connection_string)\n",
    "\n",
    "db_name = os.getenv(\"AZURE_COSMOS_DATABASE_NAME\", \"DatabaseName\")\n",
    "db = mongo_client[db_name]\n",
    "\n",
    "collection_name = os.getenv(\"AZURE_COSMOS_COLLECTION_NAME\", \"collectionName\")\n",
    "index_name = os.getenv(\"AZURE_COSMOS_INDEX_NAME\", \"indexName\")\n",
    "\n",
    "collection = db[collection_name]\n",
    "\n",
    "# Insert data\n",
    "docs = [json.loads(item.page_content) for item in json_data[0:20]]\n",
    "for doc in docs:\n",
    "    collection.insert_one(doc)\n",
    "\n",
    "# Inline generate embeddings\n",
    "collection.update_many({}, {\"$generateEmbeddings\": {\"description\": \"embeddings\"}})\n",
    "\n",
    "# Create IVF index\n",
    "createIndexCommand = {\n",
    "    \"createIndexes\": collection_name,\n",
    "    \"indexes\": [\n",
    "        {\n",
    "            \"key\": {\"embeddings\": \"cosmosSearch\"},\n",
    "            \"name\": \"ivf_index\",\n",
    "            \"cosmosSearchOptions\": {\n",
    "                \"kind\": \"vector-ivf\",\n",
    "                \"m\": 4,\n",
    "                \"efConstruction\": 16,\n",
    "                \"similarity\": \"COS\",\n",
    "                \"dimensions\": 1536,\n",
    "            },\n",
    "        }\n",
    "    ],\n",
    "}\n",
    "db.command(createIndexCommand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_pipeline = [\n",
    "    {\"$search\": {\"cosmosSearch\": {\"query\": docs[0][\"description\"], \"k\": 5, \"path\": \"embeddings\", \"efSearch\": 100}}},\n",
    "    {\"$project\": {\"similarityScore\": {\"$meta\": \"searchScore\"}, \"_id\": 0, \"name\": 1, \"description\": 1}},\n",
    "]\n",
    "\n",
    "results = collection.aggregate(search_pipeline)\n",
    "\n",
    "for result in results:\n",
    "    print(f\"[Score: {result['similarityScore']:.3f}] {result['name']}: {result['description']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
